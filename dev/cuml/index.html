<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>cuMl · RAPIDS.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://tylerjthomas9.github.io/RAPIDS.jl/cuml/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">RAPIDS.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../python_api/">Python API</a></li><li class="is-active"><a class="tocitem" href>cuMl</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#MLJ-Example-Regression"><span>MLJ Example - Regression</span></a></li><li class="toplevel"><a class="tocitem" href="#MLJ-API"><span>MLJ API</span></a></li><li><a class="tocitem" href="#Clustering"><span>Clustering</span></a></li><li><a class="tocitem" href="#Classification"><span>Classification</span></a></li><li><a class="tocitem" href="#Regression"><span>Regression</span></a></li><li><a class="tocitem" href="#Dimensionality-Reduction"><span>Dimensionality Reduction</span></a></li><li><a class="tocitem" href="#Time-Series"><span>Time Series</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>cuMl</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>cuMl</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/tylerjthomas9/RAPIDS.jl.git" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="MLJ-Example-Classification"><a class="docs-heading-anchor" href="#MLJ-Example-Classification">MLJ Example - Classification</a><a id="MLJ-Example-Classification-1"></a><a class="docs-heading-anchor-permalink" href="#MLJ-Example-Classification" title="Permalink"></a></h1><pre><code class="language-julia hljs">using RAPIDS
using MLJBase

X = rand(100, 5)
y = [repeat([0], 50)..., repeat([1], 50)...]

model = LogisticRegression()
mach = machine(model, X, y)
fit!(mach)
preds = predict(mach, X)</code></pre><h1 id="MLJ-Example-Regression"><a class="docs-heading-anchor" href="#MLJ-Example-Regression">MLJ Example - Regression</a><a id="MLJ-Example-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#MLJ-Example-Regression" title="Permalink"></a></h1><pre><code class="language-julia hljs">using RAPIDS
using MLJBase

X = rand(100, 5)
y = rand(100)

model = LinearRegression()
mach = machine(model, X, y)
fit!(mach)
preds = predict(mach, X)</code></pre><h1 id="MLJ-API"><a class="docs-heading-anchor" href="#MLJ-API">MLJ API</a><a id="MLJ-API-1"></a><a class="docs-heading-anchor-permalink" href="#MLJ-API" title="Permalink"></a></h1><ul><li><a href="#RAPIDS.KNeighborsClassifier"><code>RAPIDS.KNeighborsClassifier</code></a></li><li><a href="#RAPIDS.LinearSVC"><code>RAPIDS.LinearSVC</code></a></li><li><a href="#RAPIDS.LogisticRegression"><code>RAPIDS.LogisticRegression</code></a></li><li><a href="#RAPIDS.MBSGDClassifier"><code>RAPIDS.MBSGDClassifier</code></a></li><li><a href="#RAPIDS.RandomForestClassifier"><code>RAPIDS.RandomForestClassifier</code></a></li><li><a href="#RAPIDS.SVC"><code>RAPIDS.SVC</code></a></li></ul><h2 id="Clustering"><a class="docs-heading-anchor" href="#Clustering">Clustering</a><a id="Clustering-1"></a><a class="docs-heading-anchor-permalink" href="#Clustering" title="Permalink"></a></h2><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>KMeans``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>DBSCAN``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>AgglomerativeClustering``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>HDBSCAN``. Check Documenter&#39;s build log for details.</p></div></div><h2 id="Classification"><a class="docs-heading-anchor" href="#Classification">Classification</a><a id="Classification-1"></a><a class="docs-heading-anchor-permalink" href="#Classification" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="RAPIDS.LogisticRegression" href="#RAPIDS.LogisticRegression"><code>RAPIDS.LogisticRegression</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LogisticRegression</code></pre><p>A model type for constructing a logistic regression, based on <a href="https://github.com/tylerjthomas9/RAPIDS.jl">cuML Classification Methods.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">LogisticRegression = @load LogisticRegression pkg=cuML Classification Methods</code></pre><p>Do <code>model = LogisticRegression()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>LogisticRegression(penalty=...)</code>.</p><p><code>LogisticRegression</code> is a wrapper for the RAPIDS Logistic Regression.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with     mach = machine(model, X, y)</p><p>where</p><ul><li><p><code>X</code>: any table or array of input features (eg, a <code>DataFrame</code>) whose columns   each have one of the following element scitypes: <code>Continuous</code></p></li><li><p><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element   scitype is <code>&lt;:OrderedFactor</code> or <code>&lt;:Multiclass</code>; check the scitype   with <code>scitype(y)</code></p></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>penalty=&quot;l2&quot;</code>: Normalization/penalty function (&quot;none&quot;, &quot;l1&quot;, &quot;l2&quot;, &quot;elasticnet&quot;).<ul><li><code>none</code>: the L-BFGS solver will be used</li><li><code>l1</code>: The L1 penalty is best when there are only a few useful features (sparse), and you       want to zero out non-important features. The L-BFGS solver will be used.</li><li><code>l2</code>: The L2 penalty is best when you have a lot of important features, especially if they       are correlated.The L-BFGS solver will be used.</li><li><code>elasticnet</code>: A combination of the L1 and L2 penalties. The OWL-QN solver will be used if               <code>l1_ratio&gt;0</code>, otherwise the L-BFGS solver will be used.</li></ul></li><li>`tol=1e-4&#39;: Tolerance for stopping criteria. </li><li><code>C=1.0</code>: Inverse of regularization strength.</li><li><code>fit_intercept=true</code>: If True, the model tries to correct for the global mean of y.                        If False, the model expects that you have centered the data.</li><li><code>class_weight=&quot;balanced&quot;</code>: Dictionary or <code>&quot;balanced&quot;</code>.</li><li><code>max_iter=1000</code>: Maximum number of iterations taken for the solvers to converge.</li><li><code>linesearch_max_iter=50</code>: Max number of linesearch iterations per outer iteration used in                            the lbfgs and owl QN solvers.</li><li><code>solver=&quot;qn&quot;</code>: Algorithm to use in the optimization problem. Currently only <code>qn</code> is                supported, which automatically selects either <code>L-BFGS</code>or <code>OWL-QN</code></li><li><code>l1_ratio=nothing</code>: The Elastic-Net mixing parameter. </li><li><code>verbose=false</code>: Sets logging level.</li></ul><p><strong>Operations</strong></p><ul><li><p><code>predict(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are class assignments. </p></li><li><p><code>predict_proba(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are probabilistic, but uncalibrated.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>model</code>: the trained model object created by the RAPIDS.jl package</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><p><code>classes_seen</code>: list of target classes actually observed in training</p></li><li><p><code>features</code>: the names of the features encountered in training.</p></li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using RAPIDS
using MLJBase

X = rand(100, 5)
y = [repeat([0], 50)..., repeat([1], 50)...]

model = LogisticRegression()
mach = machine(model, X, y)
fit!(mach)
preds = predict(mach, X)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tylerjthomas9/RAPIDS.jl.git">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RAPIDS.MBSGDClassifier" href="#RAPIDS.MBSGDClassifier"><code>RAPIDS.MBSGDClassifier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MBSGDClassifier</code></pre><p>A model type for constructing a mbsgd classifier, based on <a href="https://github.com/tylerjthomas9/RAPIDS.jl">cuML Classification Methods.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">MBSGDClassifier = @load MBSGDClassifier pkg=cuML Classification Methods</code></pre><p>Do <code>model = MBSGDClassifier()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>MBSGDClassifier(loss=...)</code>.</p><p><code>MBSGDClassifier</code> is a wrapper for the RAPIDS Mini Batch SGD Classifier.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with     mach = machine(model, X, y)</p><p>where</p><ul><li><p><code>X</code>: any table or array of input features (eg, a <code>DataFrame</code>) whose columns   each have one of the following element scitypes: <code>Continuous</code></p></li><li><p><code>y</code>: is an <code>AbstractVector</code> finite target.</p></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>loss=&quot;squared_loss&quot;</code>: Loss function (&quot;hinge&quot;, &quot;log&quot;, &quot;squared_loss&quot;).<ul><li><code>hinge</code>: Linear SVM</li><li><code>log</code>: Logistic regression</li><li><code>squared_loss</code>: Linear regression</li></ul></li><li><code>penalty=&quot;none&quot;</code>: Normalization/penalty function (&quot;none&quot;, &quot;l1&quot;, &quot;l2&quot;, &quot;elasticnet&quot;).<ul><li><code>none</code>: the L-BFGS solver will be used</li><li><code>l1</code>: The L1 penalty is best when there are only a few useful features (sparse), and you       want to zero out non-important features. The L-BFGS solver will be used.</li><li><code>l2</code>: The L2 penalty is best when you have a lot of important features, especially if they       are correlated.The L-BFGS solver will be used.</li><li><code>elasticnet</code>: A combination of the L1 and L2 penalties. The OWL-QN solver will be used if               <code>l1_ratio&gt;0</code>, otherwise the L-BFGS solver will be used.</li></ul></li><li><code>alpha=1e-4</code>: The constant value which decides the degree of regularization.</li><li><code>l1_ratio=nothing</code>: The Elastic-Net mixing parameter. </li><li><code>batch_size</code>: The number of samples in each batch.</li><li><code>fit_intercept=true</code>: If True, the model tries to correct for the global mean of y.                        If False, the model expects that you have centered the data.</li><li><code>epochs=1000</code>: The number of times the model should iterate through the entire dataset during training.</li><li>`tol=1e-3&#39;: The training process will stop if current<em>loss &gt; previous</em>loss - tol.</li><li><code>shuffle=true</code>: If true, shuffles the training data after each epoch.</li><li><code>eta0=1e-3</code>: The initial learning rate.</li><li><code>power_t=0.5</code>: The exponent used for calculating the invscaling learning rate.</li><li><code>learning_rate=&quot;constant</code>: Method for modifying the learning rate during training                           (&quot;adaptive&quot;, &quot;constant&quot;, &quot;invscaling&quot;, &quot;optimal&quot;)<ul><li><code>optimal</code>: not supported</li><li><code>constant</code>: constant learning rate</li><li><code>adaptive</code>: changes the learning rate if the training loss or the validation accuracy does               not improve for n<em>iter</em>no_change epochs. The old learning rate is generally divided by 5.</li><li><code>invscaling</code>: <code>eta = eta0 / pow(t, power_t)</code></li></ul></li><li><code>n_iter_no_change=5</code>: the number of epochs to train without any imporvement in the model</li><li><code>verbose=false</code>: Sets logging level.</li></ul><p><strong>Operations</strong></p><ul><li><p><code>predict(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are class assignments. </p></li><li><p><code>predict_proba(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are probabilistic, but uncalibrated.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>model</code>: the trained model object created by the RAPIDS.jl package</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><p><code>classes_seen</code>: list of target classes actually observed in training</p></li><li><p><code>features</code>: the names of the features encountered in training.</p></li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using RAPIDS
using MLJBase

X = rand(100, 5)
y = [repeat([0], 50)..., repeat([1], 50)...]

model = MBSGDClassifier()
mach = machine(model, X, y)
fit!(mach)
preds = predict(mach, X)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tylerjthomas9/RAPIDS.jl.git">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RAPIDS.RandomForestClassifier" href="#RAPIDS.RandomForestClassifier"><code>RAPIDS.RandomForestClassifier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RandomForestClassifier</code></pre><p>A model type for constructing a random forest classifier, based on <a href="https://github.com/tylerjthomas9/RAPIDS.jl">cuML Classification Methods.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">RandomForestClassifier = @load RandomForestClassifier pkg=cuML Classification Methods</code></pre><p>Do <code>model = RandomForestClassifier()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>RandomForestClassifier(n_estimators=...)</code>.</p><p><code>RandomForestClassifier</code> is a wrapper for the RAPIDS RandomForestClassifier.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with     mach = machine(model, X, y)</p><p>where</p><ul><li><code>X</code>: any table or array of input features (eg, a <code>DataFrame</code>) whose columns   each have one of the following element scitypes: <code>Continuous</code></li><li><code>y</code>: is an <code>AbstractVector</code> finite target.</li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>n_estimators=100</code>: The total number of trees in the forest.</li><li><code>split_creation=2</code>: The criterion used to split nodes<ul><li><code>0</code> or <code>gini</code> for gini impurity</li><li><code>1</code> or <code>entropy</code> for information gain (entropy)</li></ul></li><li><code>bootstrap=true</code>: If true, each tree in the forest is built using a bootstrap sample with replacement.</li><li><code>max_samples=1.0</code>: Ratio of dataset rows used while fitting each tree.</li><li><code>max_depth=16</code>: Maximum tree depth.</li><li><code>max_leaves=-1</code>: Maximum leaf nodes per tree. Soft constraint. Unlimited, If <code>-1</code>.</li><li><code>max_features=&quot;auto&quot;</code>: Ratio of number of features (columns) to consider per node split.<ul><li>If type <code>Int</code> then max_features is the absolute count of features to be used.</li><li>If type <code>Float64</code> then <code>max_features</code> is a fraction.</li><li>If <code>auto</code> then <code>max_features=n_features = 1.0</code>.</li><li>If <code>sqrt</code> then <code>max_features=1/sqrt(n_features)</code>.</li><li>If <code>log2</code> then <code>max_features=log2(n_features)/n_features</code>.</li><li>If None, then <code>max_features=1.0</code>.</li></ul></li><li><code>n_bins=128</code>: Maximum number of bins used by the split algorithm per feature.</li><li><code>n_streams=4</code>: Number of parallel streams used for forest building</li><li><code>min_samples_leaf=1</code>: The minimum number of samples in each leaf node.<ul><li>If type <code>Int</code>, then <code>min_samples_leaf</code> represents the minimum number.</li><li>If <code>Float64</code>, then <code>min_samples_leaf</code> represents a fraction and <code>ceil(min_samples_leaf * n_rows)</code>   is the minimum number of samples for each leaf node.</li></ul></li><li><code>min_samples_split=2</code>: The minimum number of samples required to split an internal node.<ul><li>If type <code>Int</code>, then <code>min_samples_split</code> represents the minimum number.</li><li>If <code>Float64</code>, then <code>min_samples_split</code> represents a fraction and <code>ceil(min_samples_leaf * n_rows)</code>   is the minimum number of samples for each leaf node.</li></ul></li><li><code>min_impurity_decrease=0.0</code>: The minimum decrease in impurity required for node to be split.</li><li><code>max_batch_size=4096</code>: Maximum number of nodes that can be processed in a given batch.</li><li><code>random_state=nothing</code>: Seed for the random number generator.</li><li><code>verbose=false</code>: Sets logging level.</li></ul><p><strong>Operations</strong></p><ul><li><code>predict(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are class assignments. </li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>model</code>: the trained model object created by the RAPIDS.jl package</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><p><code>classes_seen</code>: list of target classes actually observed in training</p></li><li><p><code>features</code>: the names of the features encountered in training.</p></li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using RAPIDS
using MLJBase

X = rand(100, 5)
y = [repeat([0], 50)..., repeat([1], 50)...]

model = RandomForestClassifier()
mach = machine(model, X, y)
fit!(mach)
preds = predict(mach, X)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tylerjthomas9/RAPIDS.jl.git">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RAPIDS.SVC" href="#RAPIDS.SVC"><code>RAPIDS.SVC</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SVC</code></pre><p>A model type for constructing a svc, based on <a href="https://github.com/tylerjthomas9/RAPIDS.jl">cuML Classification Methods.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">SVC = @load SVC pkg=cuML Classification Methods</code></pre><p>Do <code>model = SVC()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>SVC(C=...)</code>.</p><p><code>SVC</code> is a wrapper for the RAPIDS SVC.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with     mach = machine(model, X, y)</p><p>where</p><ul><li><p><code>X</code>: any table or array of input features (eg, a <code>DataFrame</code>) whose columns   each have one of the following element scitypes: <code>Continuous</code></p></li><li><p><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element   scitype is <code>&lt;:OrderedFactor</code> or <code>&lt;:Multiclass</code>; check the scitype   with <code>scitype(y)</code></p></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>C=1.0</code>: The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.</li><li><code>kernel=&quot;rbf&quot;</code>: <code>linear</code>, <code>poly</code>, <code>rbf</code>, <code>sigmoid</code> are supported.</li><li><code>degree=3</code>: Degree of polynomial kernel function.</li><li><code>gamma=&quot;scale&quot;</code><ul><li><code>auto</code>: gamma will be set to <code>1 / n_features</code></li><li><code>scale</code>: gamma will be set to <code>1 / (n_features * var(X))</code></li></ul></li><li><code>coef0=0.0</code>: Independent term in kernel function, only signifficant for poly and sigmoid.</li><li><code>tol=0.001</code>: Tolerance for stopping criterion.</li><li><code>cache_size=1024.0</code>: Size of the cache during training in MiB.</li><li><code>class_weight=nothing</code>: Weights to modify the parameter C for class i to <code>class_weight[i]*C</code>. The string <code>&quot;balanced&quot;</code>` is also accepted.</li><li><code>max_iter=-1</code>: Limit the number of outer iterations in the solver. If <code>-1</code> (default) then <code>max_iter=100*n_samples</code>.</li><li><code>multiclass_strategy=&quot;ovo&quot;</code><ul><li><code>ovo</code>: OneVsOneClassifier</li><li><code>ovr</code>: OneVsRestClassifier</li></ul></li><li><code>nochange_steps=1000</code>: Stop training if a <code>1e-3*tol</code> difference isn&#39;t seen in <code>nochange_steps</code> steps.</li><li><code>probability=false</code>: Enable or disable probability estimates.</li><li><code>random_state=nothing</code>: Seed for the random number generator.</li><li><code>verbose=false</code>: Sets logging level.</li></ul><p><strong>Operations</strong></p><ul><li><p><code>predict(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are class assignments. </p></li><li><p><code>predict_proba(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are probabilistic, but uncalibrated.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>model</code>: the trained model object created by the RAPIDS.jl package</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><p><code>classes_seen</code>: list of target classes actually observed in training</p></li><li><p><code>features</code>: the names of the features encountered in training.</p></li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using RAPIDS
using MLJBase

X = rand(100, 5)
y = [repeat([0], 50)..., repeat([1], 50)...]

model = SVC()
mach = machine(model, X, y)
fit!(mach)
preds = predict(mach, X)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tylerjthomas9/RAPIDS.jl.git">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RAPIDS.LinearSVC" href="#RAPIDS.LinearSVC"><code>RAPIDS.LinearSVC</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LinearSVC</code></pre><p>A model type for constructing a linear svc, based on <a href="https://github.com/tylerjthomas9/RAPIDS.jl">cuML Classification Methods.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">LinearSVC = @load LinearSVC pkg=cuML Classification Methods</code></pre><p>Do <code>model = LinearSVC()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>LinearSVC(penalty=...)</code>.</p><p><code>LinearSVC</code> is a wrapper for the RAPIDS LinearSVC.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with     mach = machine(model, X, y)</p><p>where</p><ul><li><p><code>X</code>: any table or array of input features (eg, a <code>DataFrame</code>) whose columns   each have one of the following element scitypes: <code>Continuous</code></p></li><li><p><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element   scitype is <code>&lt;:OrderedFactor</code> or <code>&lt;:Multiclass</code>; check the scitype   with <code>scitype(y)</code></p></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>penalty=&quot;l2</code>: <code>l1</code> (Lasso) or <code>l2</code> (Ridge) penalty.</li><li><code>loss=&quot;squared_hinge&quot;</code>: The loss term of the target function.</li><li><code>fit_intercept=true</code>: If true, the model tries to correct for the global mean of y.                        If false, the model expects that you have centered the data.</li><li><code>penalized_intercept=true</code>: When true, the bias term is treated the same way as other features.</li><li><code>max_iter=1000</code>: Maximum number of iterations for the underlying solver.</li><li><code>linesearch_max_iter=1000</code>: Maximum number of linesearch (inner loop) iterations for the underlying (QN) solver.</li><li><code>lbfgs_memory=5</code>: Number of vectors approximating the hessian for the underlying QN solver (l-bfgs).</li><li><code>C=1.0</code>: The constant scaling factor of the loss term in the target formula <code>F(X, y) = penalty(X) + C * loss(X, y)</code>.</li><li><code>grad_tol=0.0001</code>: The threshold on the gradient for the underlying QN solver.</li><li><code>change_tol=0.00001</code>: The threshold on the function change for the underlying QN solver.</li><li><code>tol=nothing</code>: Tolerance for stopping criterion.</li><li><code>probabability=false</code>: Enable or disable probability estimates.</li><li><code>multi_class=&quot;ovo&quot;</code><ul><li><code>ovo</code>: OneVsOneClassifier</li><li><code>ovr</code>: OneVsRestClassifier</li></ul></li><li><code>verbose=false</code>: Sets logging level.</li></ul><p><strong>Operations</strong></p><ul><li><p><code>predict(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are class assignments. </p></li><li><p><code>predict_proba(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are probabilistic, but uncalibrated.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>model</code>: the trained model object created by the RAPIDS.jl package</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><p><code>classes_seen</code>: list of target classes actually observed in training</p></li><li><p><code>features</code>: the names of the features encountered in training.</p></li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using RAPIDS
using MLJBase

X = rand(100, 5)
y = [repeat([0], 50)..., repeat([1], 50)...]

model = LinearSVC()
mach = machine(model, X, y)
fit!(mach)
preds = predict(mach, X)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tylerjthomas9/RAPIDS.jl.git">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="RAPIDS.KNeighborsClassifier" href="#RAPIDS.KNeighborsClassifier"><code>RAPIDS.KNeighborsClassifier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">KNeighborsClassifier</code></pre><p>A model type for constructing a k neighbors classifier, based on <a href="https://github.com/tylerjthomas9/RAPIDS.jl">cuML Classification Methods.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">KNeighborsClassifier = @load KNeighborsClassifier pkg=cuML Classification Methods</code></pre><p>Do <code>model = KNeighborsClassifier()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>KNeighborsClassifier(algorithm=...)</code>.</p><p><code>KNeighborsClassifier</code> is a wrapper for the RAPIDS K-Nearest Neighbors Classifier.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with     mach = machine(model, X, y)</p><p>where</p><ul><li><p><code>X</code>: any table or array of input features (eg, a <code>DataFrame</code>) whose columns   each have one of the following element scitypes: <code>Continuous</code></p></li><li><p><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element   scitype is <code>&lt;:OrderedFactor</code> or <code>&lt;:Multiclass</code>; check the scitype   with <code>scitype(y)</code></p></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>n_neighbors=5</code>: Default number of neighbors to query.</li><li><code>algorithm=&quot;brute&quot;</code>: Only one algorithm is currently supported.</li><li><code>metric=&quot;euclidean&quot;</code>: Distance metric to use.</li><li><code>weights=&quot;uniform&quot;</code>: Sample weights to use. Currently, only the uniform strategy is supported.</li><li><code>verbose=false</code>: Sets logging level.</li></ul><p><strong>Operations</strong></p><ul><li><p><code>predict(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are class assignments. </p></li><li><p><code>predict_proba(mach, Xnew)</code>: return predictions of the target given   features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions   are probabilistic, but uncalibrated.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>model</code>: the trained model object created by the RAPIDS.jl package</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><p><code>classes_seen</code>: list of target classes actually observed in training</p></li><li><p><code>features</code>: the names of the features encountered in training.</p></li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using RAPIDS
using MLJBase

X = rand(100, 5)
y = [repeat([0], 50)..., repeat([1], 50)...]

model = KNeighborsClassifier()
mach = machine(model, X, y)
fit!(mach)
preds = predict(mach, X)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tylerjthomas9/RAPIDS.jl.git">source</a></section></article><h2 id="Regression"><a class="docs-heading-anchor" href="#Regression">Regression</a><a id="Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Regression" title="Permalink"></a></h2><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>LinearRegression``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>Ridge``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>Lasso``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>ElasticNet``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>MBSGDRegressor``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>RandomForestRegressor``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>CD``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>SVR``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>LinearSVR``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>KNeighborsRegressor``. Check Documenter&#39;s build log for details.</p></div></div><h2 id="Dimensionality-Reduction"><a class="docs-heading-anchor" href="#Dimensionality-Reduction">Dimensionality Reduction</a><a id="Dimensionality-Reduction-1"></a><a class="docs-heading-anchor-permalink" href="#Dimensionality-Reduction" title="Permalink"></a></h2><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>PCA``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>IncrementalPCA``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>TruncatedSVD``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>UMAP``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>TSNE``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>GaussianRandomProjection``. Check Documenter&#39;s build log for details.</p></div></div><h2 id="Time-Series"><a class="docs-heading-anchor" href="#Time-Series">Time Series</a><a id="Time-Series-1"></a><a class="docs-heading-anchor-permalink" href="#Time-Series" title="Permalink"></a></h2><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>ExponentialSmoothing``. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>-</code>ARIMA``. Check Documenter&#39;s build log for details.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../python_api/">« Python API</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Tuesday 15 November 2022 20:54">Tuesday 15 November 2022</span>. Using Julia version 1.8.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
